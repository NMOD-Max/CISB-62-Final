{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf2e720",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-10T06:58:15.202513Z",
     "iopub.status.busy": "2023-12-10T06:58:15.201860Z",
     "iopub.status.idle": "2023-12-10T06:58:47.276384Z",
     "shell.execute_reply": "2023-12-10T06:58:47.275050Z"
    },
    "papermill": {
     "duration": 32.083435,
     "end_time": "2023-12-10T06:58:47.279502",
     "exception": false,
     "start_time": "2023-12-10T06:58:15.196067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazon-fine-food-reviews/hashes.txt\n",
      "/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n",
      "/kaggle/input/amazon-fine-food-reviews/database.sqlite\n",
      "Naive Bayes Accuracy: 0.86\n",
      "Classification Report (Naive Bayes):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.23      0.33        31\n",
      "           1       0.87      0.98      0.92       169\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.75      0.60      0.63       200\n",
      "weighted avg       0.84      0.86      0.83       200\n",
      "\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 4s 64ms/step - loss: 0.6059 - accuracy: 0.7600 - val_loss: 0.4896 - val_accuracy: 0.8200\n",
      "Epoch 2/20\n",
      " 5/25 [=====>........................] - ETA: 0s - loss: 0.5791 - accuracy: 0.7563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 34ms/step - loss: 0.5422 - accuracy: 0.7700 - val_loss: 0.4852 - val_accuracy: 0.8200\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.5304 - accuracy: 0.7700 - val_loss: 0.4811 - val_accuracy: 0.8200\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 0.5266 - accuracy: 0.7700 - val_loss: 0.4809 - val_accuracy: 0.8200\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 34ms/step - loss: 0.5108 - accuracy: 0.7700 - val_loss: 0.4801 - val_accuracy: 0.8200\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.4918 - accuracy: 0.7750 - val_loss: 0.4911 - val_accuracy: 0.8100\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.4661 - accuracy: 0.7925 - val_loss: 0.5078 - val_accuracy: 0.8050\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.4305 - accuracy: 0.8250 - val_loss: 0.4930 - val_accuracy: 0.7850\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4801 - accuracy: 0.8200\n",
      "LSTM Model Accuracy: 0.8199999928474426\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "# Import necessary libraries\n",
    "# Import necessary libraries\n",
    "# ...\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load a smaller portion of the dataset (e.g., first 1000 rows)\n",
    "df = pd.read_csv('../input/amazon-fine-food-reviews/Reviews.csv', nrows=1000)\n",
    "\n",
    "# Handling missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Data Transformation\n",
    "df['Text_Length'] = df['Text'].apply(len)\n",
    "\n",
    "# Text classification using Naive Bayes\n",
    "text_data = df['Text']\n",
    "labels = df['Score'].apply(lambda score: 1 if score > 3 else 0)\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "max_words = 500\n",
    "max_len_values = [30, 50, 70]  # Adjust these values based on your experimentation\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "sequences = tokenizer.texts_to_sequences(text_data)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len_values[-1], padding='post', truncating='post')\n",
    "\n",
    "# Train-test split for Naive Bayes\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(text_data, labels, test_size=0.2, random_state=101)\n",
    "\n",
    "# Naive Bayes using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(train_texts)\n",
    "test_features = vectorizer.transform(test_texts)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_features, train_labels)\n",
    "predictions_nb = classifier.predict(test_features)\n",
    "\n",
    "# Evaluate Naive Bayes\n",
    "accuracy_nb = accuracy_score(test_labels, predictions_nb)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"Classification Report (Naive Bayes):\\n\", classification_report(test_labels, predictions_nb))\n",
    "\n",
    "# Define early stopping and model checkpoint callbacks for the LSTM model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_lstm_model.h5', save_best_only=True)\n",
    "\n",
    "# Define the LSTM model with callbacks\n",
    "def create_lstm_model(embedding_dim=50, lstm_units=32):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len_values[-1]),\n",
    "        LSTM(lstm_units),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the LSTM model with callbacks\n",
    "# Train the LSTM model with callbacks\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "lstm_model = create_lstm_model()\n",
    "lstm_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(f\"LSTM Model Accuracy: {lstm_accuracy}\")\n",
    "\n",
    "# Load the best model from the checkpoint\n",
    "best_lstm_model = create_lstm_model()\n",
    "best_lstm_model.load_weights('best_lstm_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd19064c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-10T06:58:47.308165Z",
     "iopub.status.busy": "2023-12-10T06:58:47.307677Z",
     "iopub.status.idle": "2023-12-10T06:58:47.947660Z",
     "shell.execute_reply": "2023-12-10T06:58:47.945405Z"
    },
    "papermill": {
     "duration": 0.658081,
     "end_time": "2023-12-10T06:58:47.950620",
     "exception": false,
     "start_time": "2023-12-10T06:58:47.292539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 564ms/step\n",
      "Review: This product is amazing!\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: The Food was great.\n",
      "Predicted Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use best_lstm_model for predictions\n",
    "sample_texts = [\"This product is amazing!\", \"The Food was great.\"]\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_texts)\n",
    "sample_padded_sequences = pad_sequences(sample_sequences, maxlen=max_len_values[-1], padding='post', truncating='post')\n",
    "\n",
    "sample_predictions = best_lstm_model.predict(sample_padded_sequences)\n",
    "for i, text in enumerate(sample_texts):\n",
    "    sentiment = \"Positive\" if sample_predictions[i] > 0.5 else \"Negative\"\n",
    "    print(f\"Review: {text}\\nPredicted Sentiment: {sentiment}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 18,
     "sourceId": 2157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.645383,
   "end_time": "2023-12-10T06:58:51.003892",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-10T06:58:11.358509",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
